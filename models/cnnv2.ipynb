{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "architecture-overview",
   "metadata": {},
   "source": [
    "# CNNv2: Advanced Multi-Instrument Note Analysis Pipeline\n",
    "\n",
    "This notebook implements the advanced architecture from `architecture.md` with:\n",
    "- Instrument embeddings for handling multiple instruments\n",
    "- Temporal processing with duration-aware attention\n",
    "- Variable-length spectrogram handling\n",
    "- Class balancing for imbalanced labels\n",
    "- GPU-optimized training with mixed precision\n",
    "\n",
    "## üö® IMPORTANT: GPU Training Setup\n",
    "\n",
    "**For GPU Training (recommended):**\n",
    "1. Set `TEST_MODE = False` in the config cell\n",
    "2. Ensure you have CUDA-compatible GPU with 8GB+ memory\n",
    "3. Expect ~30-60 minutes training time on modern GPU\n",
    "\n",
    "**For Testing/Development:**\n",
    "1. Set `TEST_MODE = True` (default)\n",
    "2. Safe to run on CPU/Mac for validation\n",
    "3. Only 2 epochs with small batches for quick testing\n",
    "\n",
    "## üìã Before You Start:\n",
    "- Check that the database path is correct for your system\n",
    "- Verify GPU is detected in the config cell output\n",
    "- Run the data loading test cell first to catch any issues\n",
    "- The advanced model has ~2-3M parameters and uses temporal processing\n",
    "\n",
    "## üéØ Expected Results:\n",
    "- Target accuracy: 75-85% (from architecture.md)\n",
    "- The model handles all 12 instruments and ~100 quality classes\n",
    "- Duration-aware processing for better note analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.notes_processing import generate_spectrogram\n",
    "from models.dataset import GoodSoundsDatabase, GoodSoundsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772521a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"scipy.io.wavfile\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Chunk \\\\(non-data\\\\) not understood, skipping it.\")\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"madmom\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration with test mode for development\n",
    "TEST_MODE = True  # Set to False for full GPU training\n",
    "\n",
    "if TEST_MODE:\n",
    "    print(\"üß™ TEST MODE ENABLED - Safe for CPU/Mac testing\")\n",
    "    CONFIG = {\n",
    "        'database_path': '/Users/dhanush/documents/musaic/good-sounds',\n",
    "        'batch_size': 4,  # Very small for testing\n",
    "        'num_workers': 0,  # IMPORTANT: Set to 0 for Mac/notebook compatibility\n",
    "        'learning_rate': 0.001,\n",
    "        'max_lr': 0.01,\n",
    "        'epochs': 2,  # Just 2 epochs for testing\n",
    "        'test_size': 0.2,\n",
    "        'val_size': 0.2,\n",
    "        'random_state': 42,\n",
    "        'n_fft': 512,\n",
    "        'hop_length': 128,\n",
    "        'sr': 22050\n",
    "    }\n",
    "    print(\"  - Small batch size (4)\")\n",
    "    print(\"  - Only 2 epochs\")\n",
    "    print(\"  - num_workers=0 (Mac compatibility)\")\n",
    "    print(\"  - Will work on CPU\")\n",
    "else:\n",
    "    print(\"üöÄ FULL TRAINING MODE - GPU optimized\")\n",
    "    CONFIG = {\n",
    "        'database_path': '/Users/dhanush/documents/musaic/good-sounds',\n",
    "        'batch_size': 64,  # Large batch for GPU\n",
    "        'num_workers': 8,  # More workers for GPU\n",
    "        'learning_rate': 0.001,\n",
    "        'max_lr': 0.01,\n",
    "        'epochs': 50,  # Full training\n",
    "        'test_size': 0.2,\n",
    "        'val_size': 0.2,\n",
    "        'random_state': 42,\n",
    "        'n_fft': 512,\n",
    "        'hop_length': 128,\n",
    "        'sr': 22050\n",
    "    }\n",
    "\n",
    "# Device setup with fallbacks\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    # Enable GPU optimizations only if CUDA available\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    print(\"GPU optimizations enabled\")\n",
    "else:\n",
    "    print(\"No GPU detected - using CPU mode\")\n",
    "    if not TEST_MODE:\n",
    "        print(\"‚ö†Ô∏è  WARNING: Full training on CPU will be very slow!\")\n",
    "        print(\"   Consider enabling TEST_MODE for development\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load database and get all instruments\n",
    "db = GoodSoundsDatabase(CONFIG['database_path'])\n",
    "all_df = db.get_all_sounds()\n",
    "\n",
    "print(f\"Total samples: {len(all_df)}\")\n",
    "print(f\"\\nInstruments:\")\n",
    "instrument_counts = all_df['instrument'].value_counts()\n",
    "for instrument, count in instrument_counts.items():\n",
    "    print(f\"  {instrument}: {count} samples\")\n",
    "\n",
    "print(f\"\\nTop 20 labels:\")\n",
    "label_counts = all_df['klass'].value_counts().head(20)\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"  {label}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-encoders",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instrument and label encoders\n",
    "instrument_encoder = LabelEncoder()\n",
    "instrument_encoder.fit(all_df['instrument'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_df['klass'])\n",
    "\n",
    "print(f\"Number of instruments: {len(instrument_encoder.classes_)}\")\n",
    "print(f\"Number of classes: {len(label_encoder.classes_)}\")\n",
    "\n",
    "print(f\"\\nInstrument mapping:\")\n",
    "for i, instrument in enumerate(instrument_encoder.classes_):\n",
    "    print(f\"  {i}: {instrument}\")\n",
    "\n",
    "print(f\"\\nSample label mapping (first 20):\")\n",
    "for i, label in enumerate(label_encoder.classes_[:20]):\n",
    "    print(f\"  {i}: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset-class",
   "metadata": {},
   "source": [
    "## Advanced Dataset with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiInstrumentDataset(Dataset):\n",
    "    \"\"\"Wrapper around GoodSoundsDataset that adds instrument information\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, instrument_encoder, label_encoder, \n",
    "                 spectrogram_function, cache_spectrograms=False, cache_dir=None):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.instrument_encoder = instrument_encoder\n",
    "        \n",
    "        # Create the underlying GoodSoundsDataset\n",
    "        self.base_dataset = GoodSoundsDataset(\n",
    "            dataframe, spectrogram_function, label_encoder,\n",
    "            cache_spectrograms=cache_spectrograms, cache_dir=cache_dir\n",
    "        )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get the base item from GoodSoundsDataset\n",
    "        item = self.base_dataset[idx]\n",
    "        \n",
    "        # Add instrument information from dataframe\n",
    "        row = self.df.iloc[idx]\n",
    "        instrument_id = self.instrument_encoder.transform([row['instrument']])[0]\n",
    "        \n",
    "        # Calculate duration from spectrogram (approximate)\n",
    "        spectrogram = item['spectrogram']\n",
    "        # Assuming hop_length=128 and sr=22050 from madmom defaults\n",
    "        duration = spectrogram.shape[-1] * 128 / 22050  # time_frames * hop_length / sample_rate\n",
    "        \n",
    "        return {\n",
    "            'spectrogram': item['spectrogram'],\n",
    "            'instrument_id': torch.tensor(instrument_id, dtype=torch.long),\n",
    "            'duration': torch.tensor(duration, dtype=torch.float),\n",
    "            'label': item['label'],\n",
    "            'file_path': item['file_path'],\n",
    "            'original_label': item['original_label']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collate-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function for variable-length spectrograms with instrument info\"\"\"\n",
    "    spectrograms = [item['spectrogram'] for item in batch]\n",
    "    instrument_ids = torch.stack([item['instrument_id'] for item in batch])\n",
    "    durations = torch.stack([item['duration'] for item in batch])\n",
    "    labels = torch.stack([item['label'] for item in batch])\n",
    "    \n",
    "    # Find max dimensions in batch (both freq and time can vary with madmom)\n",
    "    max_freq = max(spec.shape[-2] for spec in spectrograms)  # frequency dimension\n",
    "    max_time = max(spec.shape[-1] for spec in spectrograms)  # time dimension\n",
    "    \n",
    "    # Pad all spectrograms to same dimensions\n",
    "    padded_specs = []\n",
    "    for spec in spectrograms:\n",
    "        # Ensure spec is a tensor\n",
    "        if not isinstance(spec, torch.Tensor):\n",
    "            spec = torch.from_numpy(spec).float()\n",
    "        \n",
    "        # Add channel dimension if not present\n",
    "        if spec.dim() == 2:  # (freq, time)\n",
    "            spec = spec.unsqueeze(0)  # Add channel -> (1, freq, time)\n",
    "        elif spec.dim() == 3 and spec.shape[0] != 1:  # Wrong channel format\n",
    "            # If it's (freq, time, 1) or similar, reshape to (1, freq, time)\n",
    "            if spec.shape[2] == 1:\n",
    "                spec = spec.squeeze(2).unsqueeze(0)\n",
    "            else:\n",
    "                spec = spec.unsqueeze(0)\n",
    "        \n",
    "        # Current dimensions\n",
    "        current_freq = spec.shape[-2]\n",
    "        current_time = spec.shape[-1]\n",
    "        \n",
    "        # Pad frequency dimension (bottom padding)\n",
    "        if current_freq < max_freq:\n",
    "            freq_padding = max_freq - current_freq\n",
    "            spec = F.pad(spec, (0, 0, 0, freq_padding), value=0)  # (left, right, top, bottom)\n",
    "        elif current_freq > max_freq:\n",
    "            # Truncate frequency if somehow larger\n",
    "            spec = spec[:, :max_freq, :]\n",
    "        \n",
    "        # Pad time dimension (right padding)\n",
    "        if current_time < max_time:\n",
    "            time_padding = max_time - current_time\n",
    "            spec = F.pad(spec, (0, time_padding), value=0)  # (left, right)\n",
    "        elif current_time > max_time:\n",
    "            # Truncate time if somehow larger\n",
    "            spec = spec[:, :, :max_time]\n",
    "        \n",
    "        padded_specs.append(spec)\n",
    "    \n",
    "    # Stack all padded spectrograms\n",
    "    try:\n",
    "        stacked_specs = torch.stack(padded_specs)\n",
    "    except Exception as e:\n",
    "        print(f\"Error stacking spectrograms after padding:\")\n",
    "        for i, spec in enumerate(padded_specs):\n",
    "            print(f\"  Spec {i}: {spec.shape}\")\n",
    "        print(f\"Target shape should be: [batch_size, 1, {max_freq}, {max_time}]\")\n",
    "        raise e\n",
    "    \n",
    "    return {\n",
    "        'spectrogram': stacked_specs,\n",
    "        'instrument_id': instrument_ids,\n",
    "        'duration': durations,\n",
    "        'label': labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-architecture",
   "metadata": {},
   "source": [
    "## SimpleStarterModel Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedNoteAnalyzer(nn.Module):\n",
    "    \"\"\"Complete architecture from architecture.md with temporal processing\"\"\"\n",
    "    \n",
    "    def __init__(self, num_instruments=12, num_classes=100):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. Instrument Embedding Layer\n",
    "        # Maps instrument ID to learned 64-dim representation\n",
    "        self.instrument_embedding = nn.Embedding(num_instruments, 64)\n",
    "        \n",
    "        # 2. CNN Feature Extractor\n",
    "        # Processes variable-length spectrograms\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((8, None))  # Pool frequency only, preserve time\n",
    "        )      \n",
    "        # 3. Temporal Processing Layer\n",
    "        # Aggregates features across time (Conv1d faster than GRU on GPU)\n",
    "        self.temporal = nn.Conv1d(256*8, 512, kernel_size=3, padding=1)\n",
    "        self.temporal_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        # 4. Fusion Layer\n",
    "        # Combines audio features with instrument embedding\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(512 + 64, 512),  # features + instrument\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # 5. Classification Head\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def forward(self, spectrogram, instrument_id, duration=None):\n",
    "        batch_size = spectrogram.size(0)\n",
    "        \n",
    "        # 1. Extract CNN features\n",
    "        cnn_features = self.cnn(spectrogram)  # (batch, 256, 8, time)\n",
    "        \n",
    "        # 2. Reshape for temporal processing\n",
    "        # Flatten spatial dimensions for Conv1d\n",
    "        cnn_features = cnn_features.view(batch_size, 256*8, -1)  # (batch, 2048, time)\n",
    "        \n",
    "        # 3. Temporal processing\n",
    "        temporal_features = self.temporal(cnn_features)  # (batch, 512, time)\n",
    "        \n",
    "        # Apply duration-aware processing for better note analysis\n",
    "        if duration is not None:\n",
    "            # For short notes (< 0.5s), focus on attack (first frames)\n",
    "            # For long notes, use full temporal context\n",
    "            pooled_features = []\n",
    "            for i, dur in enumerate(duration):\n",
    "                if dur < 0.5:  # Short note - focus on attack\n",
    "                    # Take first 20% of frames or minimum 5 frames\n",
    "                    attack_frames = max(5, int(temporal_features.shape[-1] * 0.2))\n",
    "                    attack_features = temporal_features[i:i+1, :, :attack_frames]\n",
    "                    pooled = self.temporal_pool(attack_features).squeeze(-1)\n",
    "                else:  # Long note - use full context\n",
    "                    pooled = self.temporal_pool(temporal_features[i:i+1]).squeeze(-1)\n",
    "                pooled_features.append(pooled)\n",
    "            \n",
    "            pooled_temporal = torch.cat(pooled_features, dim=0)  # (batch, 512)\n",
    "        else:\n",
    "            # Standard global pooling\n",
    "            pooled_temporal = self.temporal_pool(temporal_features).squeeze(-1)  # (batch, 512)\n",
    "        \n",
    "        # 4. Get instrument embedding\n",
    "        inst_emb = self.instrument_embedding(instrument_id)  # (batch, 64)\n",
    "        \n",
    "        # 5. Fusion and classification\n",
    "        combined = torch.cat([pooled_temporal, inst_emb], dim=1)  # (batch, 576)\n",
    "        fused = self.fusion(combined)  # (batch, 512)\n",
    "        output = self.classifier(fused)  # (batch, num_classes)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "class SimpleStarterModel(nn.Module):\n",
    "    \"\"\"Simpler version for comparison - trains faster\"\"\"\n",
    "    \n",
    "    def __init__(self, num_instruments=12, num_classes=100):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Instrument embedding layer\n",
    "        self.instrument_embedding = nn.Embedding(num_instruments, 32)\n",
    "        \n",
    "        # CNN feature extractor\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1)  # Global pooling\n",
    "        )\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 + 32, 256),  # CNN features + instrument embedding\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, spectrogram, instrument_id, duration=None):\n",
    "        # Extract CNN features\n",
    "        cnn_features = self.cnn(spectrogram)  # (batch, 128, 1, 1)\n",
    "        cnn_features = cnn_features.squeeze(-1).squeeze(-1)  # (batch, 128)\n",
    "        \n",
    "        # Get instrument embedding\n",
    "        inst_emb = self.instrument_embedding(instrument_id)  # (batch, 32)\n",
    "        \n",
    "        # Combine features\n",
    "        combined = torch.cat([cnn_features, inst_emb], dim=1)  # (batch, 160)\n",
    "        \n",
    "        # Classify\n",
    "        output = self.classifier(combined)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-split",
   "metadata": {},
   "source": [
    "## Data Splitting and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified split by class (labels)\n",
    "# Filter out classes with too few samples for stratification\n",
    "min_samples = 3  # Need at least 3 samples per class for train/val/test split\n",
    "class_counts = all_df['klass'].value_counts()\n",
    "valid_classes = class_counts[class_counts >= min_samples].index\n",
    "filtered_df = all_df[all_df['klass'].isin(valid_classes)].copy()\n",
    "\n",
    "print(f\"Filtered from {len(all_df)} to {len(filtered_df)} samples\")\n",
    "print(f\"Removed {len(all_df) - len(filtered_df)} samples with insufficient class representation\")\n",
    "\n",
    "# Split data\n",
    "train_val_df, test_df = train_test_split(\n",
    "    filtered_df,\n",
    "    test_size=CONFIG['test_size'],\n",
    "    random_state=CONFIG['random_state'],\n",
    "    stratify=filtered_df['klass']\n",
    ")\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    train_val_df,\n",
    "    test_size=CONFIG['val_size'],\n",
    "    random_state=CONFIG['random_state'],\n",
    "    stratify=train_val_df['klass']\n",
    ")\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"Training: {len(train_df)} ({len(train_df)/len(filtered_df)*100:.1f}%)\")\n",
    "print(f\"Validation: {len(val_df)} ({len(val_df)/len(filtered_df)*100:.1f}%)\")\n",
    "print(f\"Testing: {len(test_df)} ({len(test_df)/len(filtered_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-datasets",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MultiInstrumentDataset wrapper with generate_spectrogram function\n",
    "spectrogram_function = generate_spectrogram\n",
    "cache_spectrograms = False  # Disable caching for now (can enable if needed)\n",
    "cache_dir = None\n",
    "\n",
    "# Create datasets using MultiInstrumentDataset wrapper\n",
    "train_dataset = MultiInstrumentDataset(\n",
    "    train_df, instrument_encoder, label_encoder, spectrogram_function,\n",
    "    cache_spectrograms=cache_spectrograms, cache_dir=cache_dir\n",
    ")\n",
    "\n",
    "val_dataset = MultiInstrumentDataset(\n",
    "    val_df, instrument_encoder, label_encoder, spectrogram_function,\n",
    "    cache_spectrograms=cache_spectrograms, cache_dir=cache_dir\n",
    ")\n",
    "\n",
    "test_dataset = MultiInstrumentDataset(\n",
    "    test_df, instrument_encoder, label_encoder, spectrogram_function,\n",
    "    cache_spectrograms=cache_spectrograms, cache_dir=cache_dir\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    collate_fn=collate_fn,\n",
    "    persistent_workers=False if CONFIG['num_workers'] == 0 else True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG['batch_size'] * 2,  # Larger batch for validation\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG['batch_size'] * 2,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(f\"Created data loaders:\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "class-weights",
   "metadata": {},
   "source": [
    "## Class Weight Calculation for Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calculate-weights",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights for imbalanced data\n",
    "y_train = train_df['klass'].apply(lambda x: label_encoder.transform([x])[0])\n",
    "unique_classes_in_train = np.unique(y_train)\n",
    "all_classes = np.arange(len(label_encoder.classes_))\n",
    "\n",
    "print(f\"Total classes in label encoder: {len(label_encoder.classes_)}\")\n",
    "print(f\"Classes present in training data: {len(unique_classes_in_train)}\")\n",
    "\n",
    "# Calculate weights only for classes present in training data\n",
    "class_weights_partial = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=unique_classes_in_train,\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "# Create full weight tensor with 1.0 for missing classes\n",
    "class_weights_full = np.ones(len(label_encoder.classes_))\n",
    "class_weights_full[unique_classes_in_train] = class_weights_partial\n",
    "\n",
    "class_weights = torch.FloatTensor(class_weights_full).to(device)\n",
    "\n",
    "print(f\"Class weights shape: {class_weights.shape}\")\n",
    "print(f\"Weight range: {class_weights.min():.3f} to {class_weights.max():.3f}\")\n",
    "print(f\"Classes with custom weights: {len(unique_classes_in_train)}\")\n",
    "print(f\"Classes with default weight (1.0): {len(all_classes) - len(unique_classes_in_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-loading",
   "metadata": {},
   "source": [
    "## Test Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-data-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data loading with safety checks\n",
    "print(\"Testing data loading...\")\n",
    "\n",
    "try:\n",
    "    # Test a single batch\n",
    "    batch = next(iter(train_loader))\n",
    "    \n",
    "    print(f\"‚úÖ Data loading successful!\")\n",
    "    print(f\"Batch shapes:\")\n",
    "    print(f\"  Spectrogram: {batch['spectrogram'].shape}\")\n",
    "    print(f\"  Instrument ID: {batch['instrument_id'].shape}\")\n",
    "    print(f\"  Duration: {batch['duration'].shape}\")\n",
    "    print(f\"  Label: {batch['label'].shape}\")\n",
    "    \n",
    "    print(f\"\\\\nSample values:\")\n",
    "    print(f\"  Instruments: {batch['instrument_id'][:min(5, len(batch['instrument_id']))]}\")\n",
    "    print(f\"  Labels: {batch['label'][:min(5, len(batch['label']))]}\")\n",
    "    print(f\"  Durations: {batch['duration'][:min(5, len(batch['duration']))].numpy()}\")\n",
    "    print(f\"  Spectrogram range: [{batch['spectrogram'].min():.3f}, {batch['spectrogram'].max():.3f}]\")\n",
    "    \n",
    "    print(f\"\\\\nüéâ Data loading test passed! Model test will happen after model initialization.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in data loading test: {e}\")\n",
    "    print(f\"\\\\nDebugging info:\")\n",
    "    print(f\"  Train dataset length: {len(train_dataset)}\")\n",
    "    print(f\"  Train loader length: {len(train_loader)}\")\n",
    "    print(f\"  Device: {device}\")\n",
    "    print(f\"  Test mode: {TEST_MODE}\")\n",
    "    \n",
    "    if TEST_MODE:\n",
    "        print(f\"\\\\nüí° This is expected in test mode - continue anyway\")\n",
    "    else:\n",
    "        print(f\"\\\\nüö® Fix these errors before full training!\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-init",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initialize-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the advanced model\n",
    "num_instruments = len(instrument_encoder.classes_)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Use the full AdvancedNoteAnalyzer model\n",
    "model = AdvancedNoteAnalyzer(num_instruments=num_instruments, num_classes=num_classes)\n",
    "\n",
    "# Alternatively, use SimpleStarterModel for faster training:\n",
    "# model = SimpleStarterModel(num_instruments=num_instruments, num_classes=num_classes)\n",
    "\n",
    "print(f\"Model initialized: AdvancedNoteAnalyzer\")\n",
    "print(f\"  Number of instruments: {num_instruments}\")\n",
    "print(f\"  Number of classes: {num_classes}\")\n",
    "print(f\"  Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"  Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# Move model to GPU if available\n",
    "model = model.to(device)\n",
    "print(f\"  Model moved to: {device}\")\n",
    "\n",
    "# Test model forward pass with a sample batch\n",
    "print(f\"\\\\nTesting model forward pass...\")\n",
    "try:\n",
    "    model.eval()\n",
    "    batch = next(iter(train_loader))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_spectrograms = batch['spectrogram'][:2].to(device)  # Take only 2 samples\n",
    "        test_instrument_ids = batch['instrument_id'][:2].to(device)\n",
    "        test_durations = batch['duration'][:2].to(device)\n",
    "        \n",
    "        outputs = model(test_spectrograms, test_instrument_ids, test_durations)\n",
    "        print(f\"‚úÖ Model forward pass successful!\")\n",
    "        print(f\"  Input shape: {test_spectrograms.shape}\")\n",
    "        print(f\"  Output shape: {outputs.shape}\")\n",
    "        print(f\"  Output range: [{outputs.min():.3f}, {outputs.max():.3f}]\")\n",
    "    \n",
    "    # Memory cleanup\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    print(f\"\\\\nüéâ Model test passed! Ready for training.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in model forward pass: {e}\")\n",
    "    if TEST_MODE:\n",
    "        print(f\"üí° Continuing in test mode...\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-setup",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_gpu(model, train_loader, val_loader, config, class_weights):\n",
    "    \"\"\"GPU-optimized training loop with CPU fallback and safety checks\"\"\"\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Mixed precision only if CUDA is available\n",
    "    use_amp = device.type == 'cuda'\n",
    "    scaler = torch.cuda.amp.GradScaler() if use_amp else None\n",
    "    \n",
    "    # Safety check for batch size vs dataset size\n",
    "    if len(train_loader) < 2:\n",
    "        print(\"‚ö†Ô∏è  WARNING: Very few training batches - consider smaller batch size\")\n",
    "    \n",
    "    # Optimizer and scheduler with safety checks\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=config['learning_rate'],\n",
    "        weight_decay=1e-4 if not TEST_MODE else 1e-5,  # Lighter regularization in test mode\n",
    "        eps=1e-8\n",
    "    )\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=config['max_lr'],\n",
    "        epochs=config['epochs'],\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.1,\n",
    "        div_factor=10,\n",
    "        final_div_factor=100\n",
    "    )\n",
    "    \n",
    "    # Loss function with class weights\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_acc': [], 'lr': []}\n",
    "    \n",
    "    print(f\"Starting training:\")\n",
    "    print(f\"  Mixed precision: {use_amp}\")\n",
    "    print(f\"  Device: {device}\")\n",
    "    print(f\"  Epochs: {config['epochs']}\")\n",
    "    print(f\"  Batch size: {config['batch_size']}\")\n",
    "    print(f\"  Steps per epoch: {len(train_loader)}\")\n",
    "    print(f\"  Test mode: {TEST_MODE}\")\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        # Use simpler progress bar in test mode\n",
    "        if TEST_MODE:\n",
    "            train_iter = enumerate(train_loader)\n",
    "            print(f\"Epoch {epoch+1}/{config['epochs']} - Training...\")\n",
    "        else:\n",
    "            train_iter = enumerate(tqdm(train_loader, desc=f'Epoch {epoch+1}/{config[\"epochs\"]} - Training'))\n",
    "        \n",
    "        for batch_idx, batch in train_iter:\n",
    "            try:\n",
    "                spectrograms = batch['spectrogram'].to(device, non_blocking=True)\n",
    "                instrument_ids = batch['instrument_id'].to(device, non_blocking=True)\n",
    "                durations = batch['duration'].to(device, non_blocking=True)\n",
    "                labels = batch['label'].to(device, non_blocking=True)\n",
    "                \n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                \n",
    "                # Mixed precision forward pass (only if GPU available)\n",
    "                if use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = model(spectrograms, instrument_ids, durations)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    outputs = model(spectrograms, instrument_ids, durations)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                scheduler.step()\n",
    "                \n",
    "                # Statistics\n",
    "                train_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "                # Progress updates\n",
    "                if TEST_MODE and batch_idx % max(1, len(train_loader)//4) == 0:\n",
    "                    train_acc = 100. * train_correct / train_total if train_total > 0 else 0\n",
    "                    print(f\"  Batch {batch_idx+1}/{len(train_loader)}: Loss={loss.item():.4f}, Acc={train_acc:.1f}%\")\n",
    "                \n",
    "                # Memory management (only for GPU)\n",
    "                if batch_idx % 50 == 0 and device.type == 'cuda':\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error in training batch {batch_idx}: {e}\")\n",
    "                if TEST_MODE:\n",
    "                    print(\"Continuing in test mode...\")\n",
    "                    continue\n",
    "                else:\n",
    "                    raise\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        if TEST_MODE:\n",
    "            print(f\"Epoch {epoch+1}/{config['epochs']} - Validation...\")\n",
    "            val_iter = enumerate(val_loader)\n",
    "        else:\n",
    "            val_iter = enumerate(tqdm(val_loader, desc=f'Epoch {epoch+1}/{config[\"epochs\"]} - Validation'))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in val_iter:\n",
    "                try:\n",
    "                    spectrograms = batch['spectrogram'].to(device, non_blocking=True)\n",
    "                    instrument_ids = batch['instrument_id'].to(device, non_blocking=True)\n",
    "                    durations = batch['duration'].to(device, non_blocking=True)\n",
    "                    labels = batch['label'].to(device, non_blocking=True)\n",
    "                    \n",
    "                    if use_amp:\n",
    "                        with torch.cuda.amp.autocast():\n",
    "                            outputs = model(spectrograms, instrument_ids, durations)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                    else:\n",
    "                        outputs = model(spectrograms, instrument_ids, durations)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += predicted.eq(labels).sum().item()\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error in validation batch {batch_idx}: {e}\")\n",
    "                    if TEST_MODE:\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        epoch_train_loss = train_loss / len(train_loader) if len(train_loader) > 0 else 0\n",
    "        epoch_val_loss = val_loss / len(val_loader) if len(val_loader) > 0 else 0\n",
    "        epoch_val_acc = 100. * val_correct / val_total if val_total > 0 else 0\n",
    "        epoch_train_acc = 100. * train_correct / train_total if train_total > 0 else 0\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        \n",
    "        # Save history\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        history['val_acc'].append(epoch_val_acc)\n",
    "        history['lr'].append(current_lr)\n",
    "        \n",
    "        print(f'\\\\nEpoch {epoch+1}/{config[\"epochs\"]} Summary:')\n",
    "        print(f'  Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}%')\n",
    "        print(f'  Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.2f}%')\n",
    "        print(f'  Learning Rate: {current_lr:.6f}')\n",
    "        \n",
    "        # GPU memory info (only if GPU available)\n",
    "        if device.type == 'cuda':\n",
    "            memory_allocated = torch.cuda.memory_allocated(device) / 1e9\n",
    "            memory_reserved = torch.cuda.memory_reserved(device) / 1e9\n",
    "            print(f'  GPU Memory: {memory_allocated:.2f}GB allocated, {memory_reserved:.2f}GB reserved')\n",
    "        \n",
    "        # Save best model\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            best_val_acc = epoch_val_acc\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'val_acc': best_val_acc,\n",
    "                'config': config,\n",
    "                'scaler_state_dict': scaler.state_dict() if scaler else None,\n",
    "                'test_mode': TEST_MODE\n",
    "            }\n",
    "            save_name = 'best_test_model.pth' if TEST_MODE else 'best_advanced_model.pth'\n",
    "            torch.save(checkpoint, save_name)\n",
    "            print(f'  ‚úì New best model saved as {save_name}! Val accuracy: {best_val_acc:.2f}%')\n",
    "        \n",
    "        # Early stopping (more aggressive in test mode)\n",
    "        early_stop_patience = 3 if TEST_MODE else 5\n",
    "        if epoch > early_stop_patience and len(history['val_loss']) > early_stop_patience:\n",
    "            recent_losses = history['val_loss'][-early_stop_patience:]\n",
    "            if all(recent_losses[i] >= recent_losses[i+1] - 0.001 for i in range(len(recent_losses)-1)):\n",
    "                print(f'  Early stopping triggered - validation loss plateaued')\n",
    "                break\n",
    "        \n",
    "        print('-' * 60)\n",
    "        \n",
    "        # Cleanup GPU memory\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "start-training",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training with mode-appropriate settings\n",
    "if TEST_MODE:\n",
    "    print(\"üß™ Starting TEST training (safe for CPU/Mac)...\")\n",
    "    print(f\"  - This will run quickly on your Mac\")\n",
    "    print(f\"  - Only {CONFIG['epochs']} epochs with small batches\")\n",
    "    print(f\"  - Perfect for testing the pipeline\")\n",
    "    print(f\"  - Change TEST_MODE=False for full GPU training\")\n",
    "else:\n",
    "    print(\"üöÄ Starting FULL GPU training...\")\n",
    "    print(f\"  - Make sure you have a powerful GPU!\")\n",
    "    print(f\"  - {CONFIG['epochs']} epochs with large batches\") \n",
    "    print(f\"  - Expected time: ~{CONFIG['epochs'] * len(train_loader) / 100:.1f} minutes on modern GPU\")\n",
    "    print(f\"  - Will save model as 'best_advanced_model.pth'\")\n",
    "\n",
    "print(f\"\\\\nTraining configuration:\")\n",
    "print(f\"  Model: AdvancedNoteAnalyzer with temporal processing\")\n",
    "print(f\"  Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"  Epochs: {CONFIG['epochs']}\")\n",
    "print(f\"  Device: {device}\")\n",
    "print(f\"  Mixed precision: {device.type == 'cuda'}\")\n",
    "\n",
    "# Confirm before starting full training\n",
    "if not TEST_MODE and device.type != 'cuda':\n",
    "    response = input(\"\\\\n‚ö†Ô∏è  WARNING: Full training on CPU will be VERY slow. Continue? (y/N): \")\n",
    "    if response.lower() != 'y':\n",
    "        print(\"Training cancelled. Consider setting TEST_MODE=True for development.\")\n",
    "        raise KeyboardInterrupt(\"Training cancelled by user\")\n",
    "\n",
    "print(f\"\\\\n{'='*60}\")\n",
    "print(f\"STARTING TRAINING\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "trained_model, history = train_model_gpu(\n",
    "    model, train_loader, val_loader, CONFIG, class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-analysis",
   "metadata": {},
   "source": [
    "## Training Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comprehensive training history\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(history['train_loss'], label='Train Loss', alpha=0.8)\n",
    "ax1.plot(history['val_loss'], label='Validation Loss', alpha=0.8)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "ax2.plot(history['val_acc'], label='Validation Accuracy', color='green', linewidth=2)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Validation Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate plot\n",
    "ax3.plot(history['lr'], label='Learning Rate', color='orange')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Learning Rate')\n",
    "ax3.set_title('Learning Rate Schedule (OneCycleLR)')\n",
    "ax3.set_yscale('log')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Loss vs Accuracy correlation\n",
    "ax4.scatter(history['val_loss'], history['val_acc'], alpha=0.6, c=range(len(history['val_acc'])), cmap='viridis') \n",
    "ax4.set_xlabel('Validation Loss')\n",
    "ax4.set_ylabel('Validation Accuracy (%)')\n",
    "ax4.set_title('Loss vs Accuracy (colored by epoch)')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Training Summary:\")\n",
    "print(f\"  Best validation accuracy: {max(history['val_acc']):.2f}%\")\n",
    "print(f\"  Final validation accuracy: {history['val_acc'][-1]:.2f}%\")\n",
    "print(f\"  Final train loss: {history['train_loss'][-1]:.4f}\")\n",
    "print(f\"  Final validation loss: {history['val_loss'][-1]:.4f}\")\n",
    "print(f\"  Total epochs completed: {len(history['val_acc'])}\")\n",
    "\n",
    "# Memory cleanup\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"  GPU memory cleared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and evaluate on test set with GPU optimizations\n",
    "checkpoint = torch.load('best_advanced_model.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "all_confidences = []\n",
    "\n",
    "print(\"Evaluating on test set...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Testing'):\n",
    "        spectrograms = batch['spectrogram'].to(device, non_blocking=True)\n",
    "        instrument_ids = batch['instrument_id'].to(device, non_blocking=True)\n",
    "        durations = batch['duration'].to(device, non_blocking=True)\n",
    "        labels = batch['label'].to(device, non_blocking=True)\n",
    "        \n",
    "        # Use mixed precision for inference too\n",
    "        if device.type == 'cuda':\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(spectrograms, instrument_ids, durations)\n",
    "        else:\n",
    "            outputs = model(spectrograms, instrument_ids, durations)\n",
    "        \n",
    "        # Get predictions and confidence scores\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        confidences, predicted = probabilities.max(1)\n",
    "        \n",
    "        test_total += labels.size(0)\n",
    "        test_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_confidences.extend(confidences.cpu().numpy())\n",
    "\n",
    "test_accuracy = 100. * test_correct / test_total\n",
    "mean_confidence = np.mean(all_confidences)\n",
    "\n",
    "print(f\"\\\\nFinal Test Results:\")\n",
    "print(f\"  Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"  Test samples: {test_total}\")\n",
    "print(f\"  Correct predictions: {test_correct}\")\n",
    "print(f\"  Mean confidence: {mean_confidence:.3f}\")\n",
    "\n",
    "# Per-class analysis\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Get class names\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "print(f\"\\\\nDetailed Classification Report:\")\n",
    "print(classification_report(all_labels, all_predictions, \n",
    "                          target_names=class_names, \n",
    "                          zero_division=0))\n",
    "\n",
    "# Top-5 and bottom-5 performing classes\n",
    "correct_per_class = np.zeros(len(class_names))\n",
    "total_per_class = np.zeros(len(class_names))\n",
    "\n",
    "for true_label, pred_label in zip(all_labels, all_predictions):\n",
    "    total_per_class[true_label] += 1\n",
    "    if true_label == pred_label:\n",
    "        correct_per_class[true_label] += 1\n",
    "\n",
    "# Avoid division by zero\n",
    "class_accuracies = np.divide(correct_per_class, total_per_class, \n",
    "                           out=np.zeros_like(correct_per_class), \n",
    "                           where=total_per_class!=0) * 100\n",
    "\n",
    "# Sort classes by accuracy\n",
    "sorted_indices = np.argsort(class_accuracies)\n",
    "\n",
    "print(f\"\\\\nTop 5 performing classes:\")\n",
    "for i in sorted_indices[-5:]:\n",
    "    if total_per_class[i] > 0:\n",
    "        print(f\"  {class_names[i]}: {class_accuracies[i]:.1f}% ({int(correct_per_class[i])}/{int(total_per_class[i])})\")\n",
    "\n",
    "print(f\"\\\\nBottom 5 performing classes:\")\n",
    "for i in sorted_indices[:5]:\n",
    "    if total_per_class[i] > 0:\n",
    "        print(f\"  {class_names[i]}: {class_accuracies[i]:.1f}% ({int(correct_per_class[i])}/{int(total_per_class[i])})\")\n",
    "\n",
    "# Memory cleanup\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model with metadata\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': CONFIG,\n",
    "    'num_instruments': num_instruments,\n",
    "    'num_classes': num_classes,\n",
    "    'instrument_encoder': instrument_encoder,\n",
    "    'label_encoder': label_encoder,\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'history': history\n",
    "}, 'cnnv2_final_model.pth')\n",
    "\n",
    "print(\"Final model saved as 'cnnv2_final_model.pth'\")\n",
    "print(f\"\\nModel Summary:\")\n",
    "print(f\"  Architecture: SimpleStarterModel with instrument embeddings\")\n",
    "print(f\"  Instruments: {num_instruments}\")\n",
    "print(f\"  Classes: {num_classes}\")\n",
    "print(f\"  Test accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"  Training samples: {len(train_dataset)}\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musaic_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
